{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWgYXQW1kuSg"
      },
      "source": [
        "# DTSA 5799 Unsupervised Text Classification for Marketing Analytics Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rfw11JBiZHi"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jpxYdJGQiWqj"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from tmtoolkit.corpus import Corpus\n",
        "    from tmtoolkit.preprocess import TMPreproc\n",
        "    from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n",
        "    from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n",
        "except ModuleNotFoundError:\n",
        "    !pip install lda\n",
        "    !pip install tmtoolkit\n",
        "    from tmtoolkit.corpus import Corpus\n",
        "    from tmtoolkit.preprocess import TMPreproc\n",
        "    from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n",
        "    from tmtoolkit.topicmod.tm_lda import compute_models_parallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8g9kSJwi7M7"
      },
      "source": [
        "## Implement a pre-processor\n",
        "\n",
        "Here you will implement a function called `preprocess` which returns the TMPreproc object to be used for topic modeling.\n",
        "\n",
        "The preprocess function will take a list of texts and return a pre-processed corpus object, i.e. a TMPreproc object. Preprocessing should include the following actions on the corpus using the appropriate methods in the TMPreproc class:\n",
        "\n",
        " - lemmatize the texts\n",
        " - convert tokens to lowercase\n",
        " - remove special characters\n",
        " - clean tokens to remove numbers and any tokens shorter than 3 characters\n",
        "\n",
        "The first part of the function to create the corpus and preprocess object are done for you. Your job is to call the specific preprocess functions and to return the resulting preprocess object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eQFevchKhohK"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts, lang=\"en\"):\n",
        "    \"\"\"Preprocessor which returns a TMPreproc object processed on corpus as language\n",
        "    specified by lang (defaults to \"en\"):\n",
        "\n",
        "    Should perform all of the following pre-processing functions:\n",
        "     - lemmatize\n",
        "     - tokens_to_lowercase\n",
        "     - remove_special_chars_in_tokens\n",
        "     - clean_tokens (remove numbers, and remove tokens shorter than 2)\n",
        "    \"\"\"\n",
        "    # Here, we just use the index of the text as the label for the corpus item\n",
        "    corpus = Corpus({ i:r for i, r in enumerate(texts) })\n",
        "\n",
        "    preproc = TMPreproc(corpus, language=lang)\n",
        "\n",
        "    TMPreproc.lemmatize(preproc)\n",
        "    TMPreproc.tokens_to_lowercase(preproc)\n",
        "    TMPreproc.remove_special_chars_in_tokens(preproc)\n",
        "    TMPreproc.clean_tokens(preproc, remove_shorter_than=3, remove_numbers=True)\n",
        "\n",
        "\n",
        "    return preproc\n",
        "\n",
        "    # TODO: Complete the implementation of this function and submit the\n",
        "    # .py download of this notebook as your assignment submission."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~~ /autograde # do not delete this cell"
      ],
      "metadata": {
        "id": "r_jJg5-xRczD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2aoBerYnF2M"
      },
      "source": [
        "---\n",
        "### ⚠️  **Caution:** No arbitrary code above this line\n",
        "\n",
        "The only code written above should be the implementation of your graded function. For experimentation and testing, only add code below.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBlUJqEan3oc"
      },
      "source": [
        "## Function development\n",
        "\n",
        "Use this section of code to verify your function implementation. You may change the test_corpus as needed to verify your implementation. The grader will be checking that your function returns a TMPreproc object that meets all of the following critera:\n",
        "\n",
        " - tokens are lemmatized\n",
        " - tokens are converted to lowercase\n",
        " - special characters are removed from tokens\n",
        " - tokens shorter than 3 characters and numerics are removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YBlpS0RsrJ3s"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-RmT0BazGQg"
      },
      "source": [
        "## Topic modeling Amazon Reviews\n",
        "\n",
        "Once you have completed the assignment above, you will be well prepared to start your final project for this unit. The project will include loading Amazon reviews into a corpus for topic modeling. The code below demonstrates topic modeling the reviews for a given brand. Note that the final project will require additional segmentation of the data, which is not done for you in the example here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpBeHmNwaMcW",
        "outputId": "66b202a3-a2a7-4133-b343-c0aadca87020"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RpcCkHX1P1d6"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import itertools\n",
        "import json\n",
        "\n",
        "asins = []\n",
        "\n",
        "# To run this code, you will need to download the metadata file from the course\n",
        "# assets and upload it to your Google Drive. See the notes about that file\n",
        "# regarding how it was processed from the original file into json-l format.\n",
        "\n",
        "with gzip.open(\"drive/MyDrive/meta_Clothing_Shoes_and_Jewelry.jsonl.gz\") as products:\n",
        "    for product in products:\n",
        "        data = json.loads(product)\n",
        "        categories = [c.lower() for c in\n",
        "                      list(itertools.chain(*data.get(\"categories\", [])))]\n",
        "        if \"nike\" in categories:\n",
        "            asins.append(data[\"asin\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the first fews ASINs"
      ],
      "metadata": {
        "id": "KysOEFGwVfIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xycViEOjR4Gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081cfbc4-7b16-4cec-eb31-2f760c2c15a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B0000V9K32', 'B0000V9K3W', 'B0000V9K46']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "asins[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the length, i.e. the number of resulting ASINs"
      ],
      "metadata": {
        "id": "P0Gska4bVj3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AIqkMoAvU-Sz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488fa730-fd8b-485c-ad6b-e58fe19c7ac6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8327"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(asins)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a corpus of review texts"
      ],
      "metadata": {
        "id": "y0bwBkHsVrsy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u6HT0Yjy3gNG"
      },
      "outputs": [],
      "source": [
        "review_corpus = []\n",
        "with gzip.open(\"drive/MyDrive/reviews_Clothing_Shoes_and_Jewelry.json.gz\") as reviews:\n",
        "    for review in reviews:\n",
        "        data = json.loads(review)\n",
        "        if data[\"asin\"] in asins:\n",
        "            text = data[\"reviewText\"]\n",
        "            review_corpus.append(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect a few of the reviews"
      ],
      "metadata": {
        "id": "hKrH89AKVwCe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A9Ct4cj7Tih9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758da18e-4589-4c31-cf34-939edc2fa7c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 the colour i received is not blue as shown but yellow.Couldnt change it because \n",
            "1 Very cute and is really practical. Fits better on smaller wrists which is my cas\n",
            "2 The watch was exactly what i ordered and I got it very fast. Unfortunately it wa\n",
            "3 This product came promptly and as described, pleasure doing business with them!-\n",
            "4 Why isn't Nike making these anymore?  I love this watch, and I get a lot of comp\n"
          ]
        }
      ],
      "source": [
        "for i, review in enumerate(review_corpus[:5]):\n",
        "    print(i, review[:80])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a TMPreproc object from the review corpus"
      ],
      "metadata": {
        "id": "q9ppd90QVzgj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "taIJ_BZU7E81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4856edb9-7495-4f5b-b734-360c0023c456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.7). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "pre = preprocess(review_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wq_-wpEE8cnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5103124-f3f4-4ad6-95ce-33f496aad5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lda:n_documents: 21570\n",
            "INFO:lda:vocab_size: 18131\n",
            "INFO:lda:n_words: 460163\n",
            "INFO:lda:n_topics: 10\n",
            "INFO:lda:n_iter: 10\n",
            "WARNING:lda:all zero row in document-term matrix found\n",
            "INFO:lda:<0> log likelihood: -4731611\n",
            "INFO:lda:<9> log likelihood: -3645141\n"
          ]
        }
      ],
      "source": [
        "dtms = {\n",
        "    \"reviews_corpus\": pre.dtm\n",
        "}\n",
        "lda_params = {\n",
        "    'n_topics': 10,\n",
        "    'eta': .01,\n",
        "    'n_iter': 10,\n",
        "    'random_state': 1234,  # to make results reproducible\n",
        "    'alpha': 1/16\n",
        "}\n",
        "\n",
        "models = compute_models_parallel(dtms, constant_parameters=lda_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the topics"
      ],
      "metadata": {
        "id": "RGRrYqRuV7nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models[\"reviews_corpus\"][0][1]\n",
        "print_ldamodel_topic_words(model.topic_word_, pre.vocabulary, top_n=5)"
      ],
      "metadata": {
        "id": "D8GYqMPHjVH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38e7ded-7df0-48cb-e950-16cba4570ebe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic_1\n",
            "> #1. shoe (0.046964)\n",
            "> #2. good (0.025713)\n",
            "> #3. great (0.019031)\n",
            "> #4. fit (0.019010)\n",
            "> #5. love (0.018058)\n",
            "topic_2\n",
            "> #1. shoe (0.036253)\n",
            "> #2. great (0.017030)\n",
            "> #3. fit (0.014959)\n",
            "> #4. buy (0.014594)\n",
            "> #5. love (0.014180)\n",
            "topic_3\n",
            "> #1. shoe (0.039852)\n",
            "> #2. good (0.013687)\n",
            "> #3. great (0.013644)\n",
            "> #4. wear (0.012543)\n",
            "> #5. size (0.011865)\n",
            "topic_4\n",
            "> #1. shoe (0.038793)\n",
            "> #2. great (0.020065)\n",
            "> #3. size (0.019479)\n",
            "> #4. love (0.018729)\n",
            "> #5. fit (0.016385)\n",
            "topic_5\n",
            "> #1. shoe (0.027436)\n",
            "> #2. watch (0.014914)\n",
            "> #3. good (0.013763)\n",
            "> #4. wear (0.012883)\n",
            "> #5. like (0.012793)\n",
            "topic_6\n",
            "> #1. shoe (0.032338)\n",
            "> #2. wear (0.014842)\n",
            "> #3. nike (0.014476)\n",
            "> #4. fit (0.014476)\n",
            "> #5. great (0.013785)\n",
            "topic_7\n",
            "> #1. shoe (0.061466)\n",
            "> #2. foot (0.019962)\n",
            "> #3. wear (0.019247)\n",
            "> #4. run (0.018513)\n",
            "> #5. good (0.016801)\n",
            "topic_8\n",
            "> #1. shoe (0.046920)\n",
            "> #2. good (0.015410)\n",
            "> #3. great (0.014826)\n",
            "> #4. wear (0.014199)\n",
            "> #5. comfortable (0.013385)\n",
            "topic_9\n",
            "> #1. shoe (0.044996)\n",
            "> #2. nike (0.015783)\n",
            "> #3. like (0.015405)\n",
            "> #4. good (0.014333)\n",
            "> #5. great (0.013493)\n",
            "topic_10\n",
            "> #1. shoe (0.027903)\n",
            "> #2. watch (0.024508)\n",
            "> #3. good (0.013873)\n",
            "> #4. nike (0.013086)\n",
            "> #5. buy (0.011647)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tpoic 1: shoe good great fit love  \n",
        "Topic 2: shoe great fit buy love  \n",
        "Tpoic 3: shoe good great wear size  \n",
        "Topic 4: shoe great size love fit  \n",
        "Tpoic 5: shoe watch good wear like  \n",
        "Topic 6: shoe wear nike fit great    \n",
        "Tpoic 7: shoe foot wear run good   \n",
        "Topic 8: shoe good great wear comfortable  \n",
        "Tpoic 9: shoe nike like good great  \n",
        "Tpoic 10: shoe watch good nike buy\n"
      ],
      "metadata": {
        "id": "70QUTRRV3O0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RE_5cnylabod"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Topic_week6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}